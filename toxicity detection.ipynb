{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "importing libraries and connecting to gpu"
      ],
      "metadata": {
        "id": "UmgrxTaMqbsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "uUdQAm2q59bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch"
      ],
      "metadata": {
        "id": "ujeQmNTaHiGL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting torch to the GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "GOvDut2yBr-9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing interface used for working with the BERT model, \n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "fWJTBzmpLxyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0iu2QAfXsyUh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "taking dataset from google drive"
      ],
      "metadata": {
        "id": "-F3IXgu1RfCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import os"
      ],
      "metadata": {
        "id": "gLOuyHP1N38T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/richard bot/dataset.csv',\n",
        "                 encoding='ISO-8859-1', \n",
        "        )"
      ],
      "metadata": {
        "id": "RlXxdtmKLZOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "LSd9flAON_xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['toxicity']).size().plot.bar()"
      ],
      "metadata": {
        "id": "NG21mZ2IPLY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('toxicity').describe()"
      ],
      "metadata": {
        "id": "soI1a7NviIf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "balancing dataset using downsampling"
      ],
      "metadata": {
        "id": "vz_KtncMiR0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_toxic = df[df['toxicity']==1]\n",
        "df_toxic.shape"
      ],
      "metadata": {
        "id": "4IlXjtPqjgwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nontoxic = df[df['toxicity']==0]\n",
        "df_nontoxic.shape"
      ],
      "metadata": {
        "id": "5gLKy4-Ejj9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_nontoxic_downsampled = df_nontoxic.sample(df_toxic.shape[0])\n",
        "df_nontoxic_downsampled.shape"
      ],
      "metadata": {
        "id": "g19mfbRljnw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#concanating the two now balanced datasets\n",
        "df_balanced = pd.concat([df_toxic, df_nontoxic_downsampled])\n",
        "df_balanced.shape"
      ],
      "metadata": {
        "id": "qoo4RvIXj4l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_balanced['toxicity'].value_counts()"
      ],
      "metadata": {
        "id": "F1mf6S81oacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating two numpy arrays with the sentences and their toxicity label\n"
      ],
      "metadata": {
        "id": "7cxLl0Jf-8wO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences= df_balanced.text.values\n",
        "labels = df_balanced.toxicity.values"
      ],
      "metadata": {
        "id": "Drvdrm1m-_kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "xFx0RBuEMBnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "2SXUNrasMEpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing the data for the BERT model - tokenizing"
      ],
      "metadata": {
        "id": "vRqiK5RGqCbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# loading the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "tIIm6zA5_Npc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizing sentences - turning into words into numbers and adding special tokens to start and end\n",
        "# special tokens: [CLS] at start, [SEP] at end\n",
        "\n",
        "#creating an array for the new sentences\n",
        "tokenized_sentences = []\n",
        "\n",
        "# for each sentence\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, \n",
        "                   )\n",
        "    \n",
        "    # adding encoded sentence to the list.\n",
        "    tokenized_sentences.append(encoded_sent)"
      ],
      "metadata": {
        "id": "BfA3XNatNfx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing the data for the BERT model - padding\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "_EuUHKrtZ9Hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 0\n",
        "b = 0\n",
        "c = 0"
      ],
      "metadata": {
        "id": "who3ypBiLkv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#seeing how many sentences are a certain length so that max_len for padding can be determined\n",
        "for sent in tokenized_sentences :\n",
        "  if len(sent) >= 512: \n",
        "    a+=1\n",
        "  elif len(sent) >= 256: \n",
        "    b+=1\n"
      ],
      "metadata": {
        "id": "l5Py0BX4qu_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6BApng4qv6n",
        "outputId": "869df4e1-ae71-428c-8bae-72889b059a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1180\n",
            "2304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "U4OgaXcFaAt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the maximum sequence length to 256\n",
        "MAX_LEN = 256\n",
        "\n",
        "# padding encoded sentences with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence instead of the beginning\n",
        "tokenized_sentences = pad_sequences(tokenized_sentences, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BnWe8KZaAq8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_sentences"
      ],
      "metadata": {
        "id": "e66E81IjPTD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparing the data for the BERT model - attention masks"
      ],
      "metadata": {
        "id": "pd94uDURPOJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#attention masks to recognize whether something is padding or not\n",
        "attention_masks = []\n",
        "\n",
        "for sent in tokenized_sentences:\n",
        "    #  mask is 0 for padding, 1 for non-zero input\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "   \n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "P2IfRx25AvLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting into train and validation set"
      ],
      "metadata": {
        "id": "KD3zlRpiVlxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZjGumUWlBEXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 90% for training and 10% for validation\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(tokenized_sentences, labels, random_state=2018, test_size=0.1)\n",
        "\n",
        "# doing the same for masks\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "_4iPUxCeVouF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting numpy arrays to tensors for model usage"
      ],
      "metadata": {
        "id": "T4OHX2RmpeOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "yfHJvudeBAS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating an iterator to save memory during training (the whole dataset wont be loaded into memory)"
      ],
      "metadata": {
        "id": "IWfIciApQZw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "wXkL787NQhaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting a batch size\n",
        "batch_size = 16\n",
        "\n",
        "# creating DataLoader for training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# creating DataLoader for validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "yRDk3N1aQNO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing a BERT model\n",
        "since it is a classifcation task (toxic or non-toxic), we use BertForSequenceClassification"
      ],
      "metadata": {
        "id": "Y-Tio5fIQs8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "metadata": {
        "id": "jSzP88AKQtSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the model with a linear classification layer on top\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # the 12-layer BERT model which does not care about uppercase or lower case\n",
        "    num_labels = 2, # the number of output labels which is 2 in this case (binary classfication)\n",
        "    output_attentions = False, \n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "# telling pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "bTpVBuoHQ_fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating an optimizer for training the model"
      ],
      "metadata": {
        "id": "e_bo9M5WRq8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # how much the weights are adjusted each time\n",
        "                  eps = 1e-8 \n",
        "                )"
      ],
      "metadata": {
        "id": "dTc4HNH8R1lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a learning rate scheduler for our model"
      ],
      "metadata": {
        "id": "ysF_1GlXSEmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "RKjVlfu9SDpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training epochs (how many times the model will be trained)\n",
        "epochs = 4\n",
        "\n",
        "# total number of training steps (number of batches * number of epochs, each epoch you train x amount of batches)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# creating the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, \n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "eb9BudhySIuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL"
      ],
      "metadata": {
        "id": "HfZ5pAyTShs1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "helper function to calculate current accuracy through every epoch"
      ],
      "metadata": {
        "id": "ugo-aFc1S7So"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "KEU02xaMSZjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "helper function for calculating elapsed times (takes time in seconds and formats it nicely)"
      ],
      "metadata": {
        "id": "-LQ4_xTVTKMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "1fpxnZyGTMPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_time(elapsed):\n",
        "    # rounding to nearest second\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # formatting to hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "3iCREproTN-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "starting the training"
      ],
      "metadata": {
        "id": "7-B5hOHmTeIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "IqPbx9pNTY1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed value is unique and makes the training reproducable\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "id": "xGeYtaYlTgRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to store the average loss after each epoch\n",
        "loss_values = []"
      ],
      "metadata": {
        "id": "rIssZACFTj73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_run = 0"
      ],
      "metadata": {
        "id": "p0bfiii8lN1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for each time you run the cell\n",
        "model_run += 1\n",
        "os.mkdir('/content/drive/My Drive/richard bot/{}'.format(model_run))\n",
        "\n",
        "# for each epoch\n",
        "for epoch_i in range(0, epochs):\n",
        "    # TRAINING STEP\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    # to measure how long each training takes\n",
        "    t0 = time.time()\n",
        "    # resetting the total loss for epoch\n",
        "    total_loss = 0\n",
        "\n",
        "    # putting the model into training mode\n",
        "    model.train()\n",
        "\n",
        "    # for every batch of data\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 32 batches.\n",
        "        if step % 200 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        #  unpacking each batch and copying the tensors to GPU (using .to)\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # clearing gradients\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # performing a forward pass (passing the training data into the model)\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # taking the loss value out of the returns\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # adding the losses of each batch (will calculate average loss at the end using this)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # doing a backwards pass to calculate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # updating parameters  based on computed gradient to minimize loss\n",
        "        # modified differently according to how optimizer is defined\n",
        "        optimizer.step()\n",
        "\n",
        "        # updating the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # caculating average loss for training data\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # storing loss values for each batch\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # VALIDATION STEP\n",
        "    # measuring performance of model after each epoch\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # putting model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # evaluating data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # adding batch GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # unpacking inputs from dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # tellinng model to not compute gradients (since we are not training model) will speed up training\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # will predict the labels or logits\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # getting the \"logits\"\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # moving logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # calculating accuracy for the current batch\n",
        "        tmp_eval_accuracy =  accuracy(logits, label_ids)\n",
        "        \n",
        "        # adding it to total accuracy\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # tracking number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # reporting the final accuracy of the validation set\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    torch.save(model,  os.path.join('/content/drive/My Drive/richard bot/{}'.format(model_run),'epoch-{}.pth'.format(epoch_i)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"TRAINING COMPLETE\")"
      ],
      "metadata": {
        "id": "8pGKhaahTuN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing the models"
      ],
      "metadata": {
        "id": "-0tOjKZko2Fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('/content/drive/My Drive/richard bot/0/epoch-0.pth')"
      ],
      "metadata": {
        "id": "gJ--T6Bho3_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = torch.load('/content/drive/My Drive/richard bot/0/epoch-1.pth')"
      ],
      "metadata": {
        "id": "ktvWMFxKo_tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = torch.load('/content/drive/My Drive/richard bot/0/epoch-2.pth')"
      ],
      "metadata": {
        "id": "_BjWZToqo_hA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# creating sentence and label lists\n",
        "sentences = [\"love you\",\"fuck you\",\"you're a loser\",\"you're so cool\"]\n",
        "labels = [0,1,1,0]\n",
        "\n",
        "# tokenizing\n",
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                \n",
        "                        add_special_tokens = True,\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# padding\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# creating attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# converting to tensor\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# setting batch size\n",
        "batch_size = 16\n",
        "\n",
        "# creating DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "iENMdaw6o6-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# putting model in evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # unpacking inputs from dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  #making predictions\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # moving logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # storing predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n"
      ],
      "metadata": {
        "id": "lplKuAyJo7gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# turning predictions into 0 for nontoxic and 1 for toxic\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()"
      ],
      "metadata": {
        "id": "g6L3dg7Zp4mJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agzwWgzzusFt",
        "outputId": "d727aee9-e654-4422-f504-469574b6bde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UAfNsVhJusTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}